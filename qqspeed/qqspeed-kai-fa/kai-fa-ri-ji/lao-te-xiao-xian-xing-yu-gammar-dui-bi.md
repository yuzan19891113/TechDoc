# 老特效线性与Gammar对比

![](../../../.gitbook/assets/image%20%2811%29.png)

**EffectsRTAnalyzer，EffectsToRT：**

1. 进入编辑器Playing状态，2个相机，gamma, linear,同一帧模拟数据，不同的RT,
2. 挂在主相机的后处理，几次Blit将线性的结果转为gamma,然后转LAB空间 操作，按照需求显示在屏幕
3.  回读结果分析，得到单帧数据
4.  特效帧更新，特效播放结束换相机方向（前后，上下，左右相机）重新开始，

Lab：感知均匀，L分量：亮度， A, 红到绿的比例 B蓝到黄比例，对比颜色空间，从rgb-&gt;hsv-&gt;lab

**数据处理：**

首先剔除掉数值变化较小的像素，避免小数淹没大数，

结果处理方法:

![](../../../.gitbook/assets/image%20%2818%29.png)



* 得到每帧LAB差异总量，差异均值，6组数据
* 取相机前，上，左的每帧结果数据的Max

目录：Assets/ResForAssetBundles/Effects; Assets/ArtWork/Effects，

总的Prefab 个数 34150， 去掉纯引用的Prefab：还有20949

阈值：基本还是经验值，没法说用一个科学的方法来评估，但要往尽量科学靠，现在的都是自己根据强哥最开始给的一版数据自己设定的。

```text
           //对于变化面积小且平均变化还能接受的特效
           Vector3 LabTotalParam1 = new Vector3(10, 2.5f, 2.5f);
           Vector3 LabAVGParam1 = new Vector3(0.14f, 0.03f, 0.03f);
           
           //对于平均变化比较小且变化面积不大的特效
           Vector3 LabAVGParam2 = new Vector3(0.07f, 0.015f, 0.015f);
           Vector3 LabTotalParam2 = new Vector3(500, 100f, 100f);
```

使用256 \* 256来作为计算和分析rt，**为啥选用256 \* 256**

基本上呈现一种scale的差异，分辨率对均值影响不大，并且256 \*256是现在唯一有8,9帧的。

![](../../../.gitbook/assets/image%20%2820%29.png)

![](../../../.gitbook/assets/image%20%2841%29.png)

![](../../../.gitbook/assets/image%20%2825%29.png)

目标：**输出安全的特效保证结果正确，输出最有问题的特效来给美术修改**

给美术提供gamma和线性下的结果

数据对比分析，显示结果与数据对比

![Linear](../../../.gitbook/assets/image%20%2812%29.png)

![Diff\_L](../../../.gitbook/assets/image%20%2823%29.png)

![Diff\_A](../../../.gitbook/assets/image%20%2834%29.png)

![](../../../.gitbook/assets/image%20%2831%29.png)

![](../../../.gitbook/assets/image%20%2829%29.png)

**图中总值110 &gt;阈值100， B均值0.022大于0.015，标记为需要修改的特效**

能通过的特效：

![Gamma](../../../.gitbook/assets/image%20%2833%29.png)

![ Linear](../../../.gitbook/assets/image%20%2813%29.png)

![](../../../.gitbook/assets/image%20%2840%29.png)



**初步的一些结论：**

1. 强哥给的特效都能判断出来，单向的验证，坏的特效一定不能通过验证，

   2 初步的小规模测试结果：刚测的FX\_Pet目录，总数3363，跑完到17.69%， 测试数量595， good数量是206， miss数量31\(待查,特效可能未播出来或其他原因未显示在镜头吧\)，大概能不改的比例为34.7%，前天测过一次更大规模的，大概跑了10000多个，有5000多个是安全的，不过这是avatar里的特效里的，估计大部分是小特效，其他pet里抽的子文件大概为30-40%左右，希望星期天跑一下能得到个全量数据看一下。还没有全量，因为现在速度太慢，一个得3-6秒。20000多个就得十几万秒

**初步结论：大概有30%-50%的不需要修改，小特效会接近50%，**

存在的问题：

1移动较快或者并且本身就有亮度或者颜色的变化，就会造成单帧差异大，数据可能表现差异大，整体不明显，

2 效果变好了，没法感知，现在只是能够整体接受变亮一些,但是我们接受的美术能否接受

3 基本上大部分大特效都会标注为要修改，因为，不仅变化大，而且可能总量大，这个好像没法避免，

思考和计划：

* 给美术提供我的数据来验证我得到结论安全的特效美术也认为可以，**双向验证**
* 同时能够出一个最差的一批特效优先改
* 趁着星期天出一个全量测试看一下有多少特效可以不改，
* 是否可以策划或者美术，运营给个优先级，按照优先级来设定不同的要求，重要的特效容差度低点
* 需要加速，每个特效现在需要6s，并且运行帧率只有9帧
* 是否需要提供美术工具快速对比特效差异，现在估计美术挺慢的
* 数据阈值选取能否更加科学

其他一些问题：

我们的lod不是自动的，而是不同的资源，是否会增加包量



